{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":253895,"status":"ok","timestamp":1671101551829,"user":{"displayName":"Vishwaksena Vishnu Simha Dingari","userId":"12421495256767091464"},"user_tz":-330},"id":"1LYJIVyUy_Dl","outputId":"a9241ce6-e489-471b-f65c-6551a5981624"},"outputs":[{"ename":"ModuleNotFoundError","evalue":"No module named 'google'","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[1;32mc:\\Users\\kosanam\\OneDrive\\Desktop\\test\\project_VGG16.ipynb Cell 1\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/kosanam/OneDrive/Desktop/test/project_VGG16.ipynb#W0sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mgoogle\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcolab\u001b[39;00m \u001b[39mimport\u001b[39;00m drive\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/kosanam/OneDrive/Desktop/test/project_VGG16.ipynb#W0sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m drive\u001b[39m.\u001b[39mmount(\u001b[39m'\u001b[39m\u001b[39m/content/drive\u001b[39m\u001b[39m'\u001b[39m)\n","\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'google'"]}],"source":["# from google.colab import drive\n","# drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":684,"status":"ok","timestamp":1671101552508,"user":{"displayName":"Vishwaksena Vishnu Simha Dingari","userId":"12421495256767091464"},"user_tz":-330},"id":"na0A1pOGVRne"},"outputs":[],"source":["# !rm -rf sample_data\n","# !rm -rf segmented\n","# !rm -rf segmented_224\n","# !rm -rf random.png random_data.png"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hnHeiT3xVTSJ"},"outputs":[],"source":["# !unzip '/content/drive/MyDrive/Colab Notebooks/Final_Year_Project/combined_segmented.zip'\n","# !unzip '/content/drive/MyDrive/Colab Notebooks/Final_Year_Project/png.zip'\n","# !unzip '/content/drive/MyDrive/Colab Notebooks/Final_Year_Project/bw_segmented.zip'"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1671101568796,"user":{"displayName":"Vishwaksena Vishnu Simha Dingari","userId":"12421495256767091464"},"user_tz":-330},"id":"jIAGmkZ5zGGu"},"outputs":[],"source":["# import os\n","\n","# root_dir = os.listdir()\n","# # os.rename('combined_segmented', 'segmented')\n","# # os.rename('png', 'segmented')\n","# os.rename('bw_segmented', 'segmented')"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"w7kavFP6VvFD"},"outputs":[{"name":"stdout","output_type":"stream","text":["c:\\Users\\kosanam\\OneDrive\\Desktop\\test\n","58482\n","58317\n","165\n","0\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\kosanam\\AppData\\Local\\Temp\\ipykernel_12708\\2057255070.py:43: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning dissapear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n","  image =imread(image_path)\n"]},{"name":"stdout","output_type":"stream","text":["1 2 3 4 5 6 7 8 9 10\n","11 12 13 14 15 16 17 18 19 20\n","21 22 23 24 25 26 27 28 29 30\n","31 32 33 34 35 36 37 38 39 40\n","41 42 43 44 45 46 47 48 49 50\n","51 52 53 54 \n"]}],"source":["# Loading the data and generating labels\n","import numpy as np\n","import os\n","from imageio import imread\n","from keras.applications.vgg16 import preprocess_input\n","from keras.utils import to_categorical \n","from skimage.transform import resize\n","import glob\n","import cv2\n","import random\n","\n","IMG_SIZE = 32\n","no_of_classes = 55\n","image_height, image_width = IMG_SIZE, IMG_SIZE\n","no_of_color_channels = 3\n","root_dir = os.getcwd()\n","print(root_dir)\n","\n","total_no_of_images = len(list(glob.glob(root_dir+\"/segmented/[0-9]*/\"+\"/*.png\", recursive=True)))\n","print(total_no_of_images)\n","\n","count = 0\n","train_size = total_no_of_images - no_of_classes*3\n","data = np.empty((train_size, image_height, image_width, no_of_color_channels))\n","labels = np.empty(train_size, dtype=int)\n","\n","test_count = 0\n","test_data = np.empty((no_of_classes*3, image_height, image_width, no_of_color_channels))\n","test_labels = np.empty(no_of_classes*3, dtype=int)\n","\n","print(train_size)\n","print(no_of_classes*3)\n","\n","r = random.randrange(total_no_of_images)\n","for i in range(no_of_classes):\n","    class_dir = root_dir + \"/\" + \"segmented\" + \"/\" + str(i)\n","    class_images = glob.glob(class_dir+'/*.png')\n","    size = len(class_images)\n","    if (i % 10 == 0): print(i)\n","    else: print(i, end=' ')\n","    for j in range(size):\n","        image_path = class_images[j]\n","        image =imread(image_path)\n","        # if len(image.shape) > 2 and image.shape[2] == 4:\n","        #     image = cv2.cvtColor(image, cv2.COLOR_BGRA2BGR)\n","        # image = resize(image, output_shape=(IMG_SIZE, IMG_SIZE))\n","        if count == r:\n","          cv2.imwrite(root_dir+'/random.png',image)\n","        image = preprocess_input(image)\n","        # image = resize(image, output_shape=(IMG_SIZE, IMG_SIZE))\n","        if j < size-3: \n","          data[count] = image\n","        else:\n","          test_data[test_count] = image\n","        if count == r:\n","          cv2.imwrite(root_dir+'/random_data.png',image)\n","        if j < size-3:\n","          labels[count] = i\n","          count+=1\n","        else:\n","          test_labels[test_count] = i\n","          test_count+=1\n","print('')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VGC7rdzkWKUT"},"outputs":[],"source":["# np.save(root_dir+'/data.npy', data)\n","# np.save(root_dir+'/labels.npy', labels)\n","# np.save(root_dir+'/test_data.npy', test_data)\n","# np.save(root_dir+'/test_labels.npy', test_labels)\n","# # data = np.load(root_dir+'/data.npy')\n","# # labels = np.load(root_dir+'/labels.npy')"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"PXuKlkJIWOCB"},"outputs":[{"name":"stdout","output_type":"stream","text":["(32, 32, 3)\n","-123.68000030517578\n","151.06100463867188\n","[ 0  0  0 ... 54 54 54]\n","165 (32, 32, 3)\n","[ 0  0  0  1  1  1  2  2  2  3  3  3  4  4  4  5  5  5  6  6  6  7  7  7\n","  8  8  8  9  9  9 10 10 10 11 11 11 12 12 12 13 13 13 14 14 14 15 15 15\n"," 16 16 16 17 17 17 18 18 18 19 19 19 20 20 20 21 21 21 22 22 22 23 23 23\n"," 24 24 24 25 25 25 26 26 26 27 27 27 28 28 28 29 29 29 30 30 30 31 31 31\n"," 32 32 32 33 33 33 34 34 34 35 35 35 36 36 36 37 37 37 38 38 38 39 39 39\n"," 40 40 40 41 41 41 42 42 42 43 43 43 44 44 44 45 45 45 46 46 46 47 47 47\n"," 48 48 48 49 49 49 50 50 50 51 51 51 52 52 52 53 53 53 54 54 54]\n"]},{"data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAZcAAADECAYAAABTC2zgAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAE40lEQVR4nO3dQU7jShRAUfzFYmEBMIIRPWoWALt1D7v1lUBCrpOyfc4wMpFVCroq+aUyzfM83wFA6L9b3wAA2yMuAOTEBYCcuACQExcAcuICQE5cAMiJCwA5cQEgd3/rG2B80zQdfN3hDj/z+f7r1rfAjTw+vx58/eP325Xv5DIPTy/fXmPnAkBOXADIiQsAOXEBICcuAOTEBYCcuACQExcAcuICQG7Yb+gf+1b4NW3lG+hLreU577uVtVyjY98Kv6a1fQP9mKXW8pz3Xcta2rkAkBMXAHLiAkBOXADIiQsAuWGnxTjfCBN2sAUjTNitnZ0LADlxASAnLgDkxAWA3M0f6I/8EPrQvTnG5Ges5fJGfgh96N7WcozJaNaylnYuAOTEBYCcuACQExcAcuICQG6aFxjZGXkC7JqWnIba2xpvabLs8/3XydeOPAF2TUtOQ+1tjYu1fHh6+fYaOxcAcuICQE5cAMiJCwC5mx//wtf29uAelrK3B/e3ZucCQE5cAMiJCwA5cQEgJy4A5EyLsQrHpua2dCwMXMOxqbn6iB07FwBy4gJATlwAyIkLALmLH+g7nuQ4D6GXd2iN17q+jic57loPoffs0Bpfsr52LgDkxAWAnLgAkBMXAHLiAkDO8S83YMIOGibsxmXnAkBOXADIiQsAOXEBICcuAOTEBYCcuACQExcAcuICQE5cAMiJCwA5cQEgJy4A5MQFgJy4AJATFwBy4gJATlwAyIkLADlxASAnLgDkxAWAnLgAkBMXAHLiAkBOXADI3Z964TRNS94H7Mbj8+utbwEWZ+cCQE5cAMiJCwA5cQEgJy4A5MQFgJy4AJATFwBy4gJATlwAyJ18/MvazPN88rWOtvnLuvF/H7/fTr7W0TZ/7X3d7FwAyIkLADlxASAnLgDkxAWA3GanxfjaOVNh57yHCTL25pypsHPeY+0TZHYuAOTEBYCcuACQExcAcuICQG4T02KXTj4d+3uTT+zNpZNPx/5+7ZNPnM/OBYCcuACQExcAcuICQE5cAMiJCwA5cQEgJy4A5MQFgJy4AJDbxPEvS9nKj2EVPwwGl9jKj2EVPwy2F3YuAOTEBYCcuACQExcActN84tPekR9kj/DAeoT1sQ5fG2F97u7GXqMRHliP8KDfOnztlP8lOxcAcuICQE5cAMiJCwA5cQEgJy4A5MQFgJy4AJATFwBy4gJAzu+5rNQoR5nA2o1w1MsW2bkAkBMXAHLiAkBOXADIiQsAOXEBICcuAOTEBYCcuACQExcAcuICQE5cAMiJCwA5cQEgJy4A5MQFgJy4AJATFwBy4gJATlwAyIkLALn7Uy+c5/ng69M0ZTfz03uAf43+Ofn4/Xbw9cfn15vfA/zrks+JnQsAOXEBICcuAOTEBYCcuACQO3lajK8dmlC65iTdXo0+Gcb5Dk0oXXOSbq/qCUI7FwBy4gJATlwAyIkLADkP9Bc0wpE5sAUjHJnDeexcAMiJCwA5cQEgJy4A5MQFgNw0L3B+xlLTUI762Ja9fk4+33+dfO1S01B+LGxbrv05eXh6+fZv7VwAyIkLADlxASAnLgDkhj3+ZfSHsrAWHt5zC3YuAOTEBYCcuACQExcAcuICQG6R418A2Dc7FwBy4gJATlwAyIkLADlxASAnLgDkxAWAnLgAkBMXAHJ/AGFd1zUbdiz/AAAAAElFTkSuQmCC","text/plain":["<Figure size 500x500 with 2 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["import matplotlib.pyplot as plt\n","%matplotlib inline\n","\n","print(data[random.randrange(total_no_of_images)].shape)\n","fig = plt.figure(figsize=(5, 5))\n","fig.add_subplot(1, 2, 1)\n","plt.imshow(cv2.imread(root_dir+'/random.png'))\n","plt.axis('off')\n","fig.add_subplot(1, 2, 2)\n","plt.imshow(cv2.imread(root_dir+'/random_data.png'))\n","plt.axis('off')\n","print(data.min())\n","print(data.max())\n","print(labels)\n","print(len(test_data), test_data[random.randrange(no_of_classes)].shape)\n","print(test_labels)"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":667,"status":"ok","timestamp":1671103138200,"user":{"displayName":"Vishwaksena Vishnu Simha Dingari","userId":"12421495256767091464"},"user_tz":-330},"id":"cuc0R4WqYsG5"},"outputs":[{"name":"stdout","output_type":"stream","text":["Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n","58889256/58889256 [==============================] - 7s 0us/step\n"]}],"source":["# Importing VGG16\n","from keras.applications.vgg16 import VGG16\n","\n","IMG_SHAPE = (IMG_SIZE, IMG_SIZE, 3)\n","base_model = VGG16(\n","    input_shape=IMG_SHAPE,\n","    include_top=False,\n","    weights='imagenet'\n",")\n","base_model.trainable = False\n","# base_model.summary()"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"MEH9fheYWQS1"},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," vgg16 (Functional)          (None, 1, 1, 512)         14714688  \n","                                                                 \n"," flatten (Flatten)           (None, 512)               0         \n","                                                                 \n"," dense (Dense)               (None, 256)               131328    \n","                                                                 \n"," dropout (Dropout)           (None, 256)               0         \n","                                                                 \n"," dropout_1 (Dropout)         (None, 256)               0         \n","                                                                 \n"," dense_1 (Dense)             (None, 128)               32896     \n","                                                                 \n"," dense_2 (Dense)             (None, 55)                7095      \n","                                                                 \n","=================================================================\n","Total params: 14,886,007\n","Trainable params: 171,319\n","Non-trainable params: 14,714,688\n","_________________________________________________________________\n"]}],"source":["# # Modifying the model\n","from keras import Model\n","from keras.layers import Dense, Flatten, Dropout\n","from keras import layers, models\n","\n","\n","# character_output = Dense(no_of_classes, activation='softmax')\n","# character_output = character_output(base_model.layers[-2].output)\n","# character_input = base_model.input\n","# character_model = Model(inputs=character_input, outputs=character_output)\n","# for layer in character_model.layers[:-1]:\n","#   layer.trainable = False\n","\n","\n","flatten_layer = Flatten()\n","dense_layer_1 = Dense(256, activation='relu')\n","dropout_layer_1 = Dropout(0.4)\n","dense_layer_2 = Dense(128, activation='relu')\n","dropout_layer_2 = Dropout(0.6)\n","prediction_layer = Dense(55, activation='softmax')\n","\n","# character_model = models.Sequential([\n","#     base_model,\n","#     flatten_layer,\n","#     dense_layer_1,\n","#     dense_layer_2,\n","#     prediction_layer\n","# ])\n","# character_model.summary()\n","\n","# flatten_layer = layers.Flatten()\n","# dense_layer_1 = layers.Dense(64, activation='relu')\n","# prediction_layer = layers.Dense(55, activation='softmax')\n","\n","character_model = models.Sequential([\n","    base_model,\n","    flatten_layer,\n","    dense_layer_1,\n","    dropout_layer_1,\n","    \n","    dropout_layer_2,\n","    dense_layer_2,\n","    prediction_layer\n","])\n","character_model.summary()\n"]},{"cell_type":"code","execution_count":35,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1671103141273,"user":{"displayName":"Vishwaksena Vishnu Simha Dingari","userId":"12421495256767091464"},"user_tz":-330},"id":"AHn2B-OzWSoN"},"outputs":[],"source":["# Compiling the model\n","from keras.optimizers import Adam\n","custom_adam = Adam(learning_rate=0.0001)\n","character_model.compile(\n","    loss='sparse_categorical_crossentropy',\n","    optimizer=custom_adam,\n","    metrics=['accuracy']\n",")"]},{"cell_type":"code","execution_count":36,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1671103143513,"user":{"displayName":"Vishwaksena Vishnu Simha Dingari","userId":"12421495256767091464"},"user_tz":-330},"id":"UaYjbLEsvPbK"},"outputs":[],"source":["# EarlyStopping\n","from keras.callbacks import EarlyStopping\n","\n","es = EarlyStopping(monitor='val_accuracy', mode='max', patience=5,  restore_best_weights=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"y8AAEvyuWUbb"},"outputs":[],"source":["# Training the model\n","history = character_model.fit(\n","    x=data,\n","    y=labels,\n","    epochs=200,\n","    verbose='auto',\n","    validation_split=0.1,\n","    shuffle=True, \n","    callbacks=[es],\n","    batch_size=32\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WAurau9upIvU"},"outputs":[],"source":["print(history.history.keys())\n","loss_train = history.history['loss']\n","loss_val = history.history['val_loss']\n","epochs = range(10)\n","plt.plot(epochs, loss_train, 'g', label='Training Loss')\n","plt.plot(epochs, loss_val, 'b', label='Validation Loss')\n","plt.title('Training and Validation Loss')\n","plt.xlabel('Epochs')\n","plt.ylabel('Loss')\n","plt.legend()\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5QvgxcL41nKt"},"outputs":[],"source":["print(history.history.keys())\n","loss_train = history.history['accuracy']\n","loss_val = history.history['val_accuracy']\n","epochs = range(10)\n","plt.plot(epochs, loss_train, 'g', label='Training Accuracy')\n","plt.plot(epochs, loss_val, 'b', label='Validation Accuracy')\n","plt.title('Training and Validation Accuracy')\n","plt.xlabel('Epochs')\n","plt.ylabel('Accuracy')\n","plt.legend()\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"A49OXQuF6WWO"},"outputs":[],"source":["character_model.save('character_model_vgg16.h5')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gW11h2nk5sfE"},"outputs":[],"source":["predictions = character_model.predict(test_data)\n","print('Shape: {}'.format(predictions.shape))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CT6jf6d_5vRq"},"outputs":[],"source":["for i in range(no_of_classes):\n","  output_neuron = np.argmax(predictions[i])\n","  print('Most active neuron: {} ({:.2f}%)'.format(\n","      output_neuron,\n","      100 * predictions[i][output_neuron]\n","  ))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"724EEP_5t3HZ"},"outputs":[],"source":["top1_correct = 0\n","top1_incorrect = 0\n","top5_correct = 0\n","top5_incorrect = 0\n","for i in range(no_of_classes*3):\n","  s = set()\n","  sorted_predictions = np.sort(predictions[i])[::-1]\n","  for j in range(5):\n","    x = list(np.where(predictions[i]==sorted_predictions[j]))[0][0]\n","    s.add(x)\n","  # print(list(s))\n","  if test_labels[i] in s: top5_correct+=1\n","  else: top5_incorrect+=1\n","  if test_labels[i] == np.argmax(predictions[i]): top1_correct+=1\n","  else: top1_incorrect+=1\n","\n","print('Top-1 Accuracy: ', (top1_correct*100)/(top1_correct+top1_incorrect))\n","print('Top-5 Accuracy: ', (top5_correct*100)/(top5_correct+top5_incorrect))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aRrRLujuyamC"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"base","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.7"},"vscode":{"interpreter":{"hash":"7d617dbb1411950ab405bea578227d5cd1abd8d3c3a321351caec86a3bbc3194"}}},"nbformat":4,"nbformat_minor":0}
